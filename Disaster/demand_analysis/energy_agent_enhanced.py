"""
Enhanced Energy Demand Analysis AI Agent
Supports multiple ML models: CNN, LSTM, TFT
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.ensemble import IsolationForest, RandomForestRegressor
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

class EnergyDemandAgentEnhanced:
    def __init__(self, data_path, model_type='RandomForest'):
        self.data_path = data_path
        self.model_type = model_type
        self.raw_data = None
        self.clean_data = None
        self.quality_report = {}
        self.anomalies = None
        self.predictions = None
        self.model = None
        self.scaler = StandardScaler()
        self.minmax_scaler = MinMaxScaler()
        
    def load_data(self):
        """Load and perform initial data inspection"""
        print("ðŸ”„ Loading data...")
        self.raw_data = pd.read_csv(self.data_path)
        
        # Try to find relevant columns with flexible matching
        time_col = None
        energy_col = None
        power_col = None
        
        # Find time column
        for col in self.raw_data.columns:
            col_lower = col.lower()
            if 'time' in col_lower or 'date' in col_lower or 'timestamp' in col_lower:
                time_col = col
                break
        
        # Find energy column
        for col in self.raw_data.columns:
            col_lower = col.lower()
            if 'kwh' in col_lower or 'energy' in col_lower or 'consumption' in col_lower:
                energy_col = col
                break
        
        # Find power column
        for col in self.raw_data.columns:
            col_lower = col.lower()
            if 'kw' in col_lower and 'kwh' not in col_lower or 'power' in col_lower:
                power_col = col
                break
        
        # Rename columns if found
        if time_col and time_col != 'time':
            self.raw_data = self.raw_data.rename(columns={time_col: 'time'})
        if energy_col and energy_col != 'kWh':
            self.raw_data = self.raw_data.rename(columns={energy_col: 'kWh'})
        if power_col and power_col != 'kW':
            self.raw_data = self.raw_data.rename(columns={power_col: 'kW'})
        
        # Keep relevant columns
        relevant_cols = ['time', 'kWh', 'kW', 'year', 'month', 'day']
        available_cols = [col for col in relevant_cols if col in self.raw_data.columns]
        
        # Add other columns if needed
        if len(available_cols) < 3:
            # Add first numeric column as kWh if not found
            numeric_cols = self.raw_data.select_dtypes(include=['number']).columns
            if 'kWh' not in available_cols and len(numeric_cols) > 0:
                available_cols.append(numeric_cols[0])
                self.raw_data = self.raw_data.rename(columns={numeric_cols[0]: 'kWh'})
        
        self.raw_data = self.raw_data[available_cols] if len(available_cols) > 0 else self.raw_data
        
        print(f"âœ… Loaded {len(self.raw_data)} records")
        return self.raw_data
    
    def validate_data_quality(self):
        """Comprehensive data quality validation"""
        print("\nðŸ” Validating data quality...")
        
        report = {
            'total_records': len(self.raw_data),
            'missing_values': {},
            'duplicates': 0,
            'outliers': {},
            'data_types': {},
            'date_range': {},
            'quality_score': 0
        }
        
        # Check missing values
        for col in self.raw_data.columns:
            missing = self.raw_data[col].isnull().sum()
            missing_pct = (missing / len(self.raw_data)) * 100 if len(self.raw_data) > 0 else 0
            report['missing_values'][col] = {
                'count': int(missing),
                'percentage': round(missing_pct, 2)
            }
        
        # Check duplicates
        report['duplicates'] = int(self.raw_data.duplicated().sum())
        
        # Check data types
        for col in self.raw_data.columns:
            report['data_types'][col] = str(self.raw_data[col].dtype)
        
        # Check numeric outliers
        numeric_cols = self.raw_data.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if col in ['kWh', 'kW'] or 'kWh' in col or 'kW' in col:
                Q1 = self.raw_data[col].quantile(0.25)
                Q3 = self.raw_data[col].quantile(0.75)
                IQR = Q3 - Q1
                if IQR > 0:
                    outliers = ((self.raw_data[col] < (Q1 - 1.5 * IQR)) | 
                               (self.raw_data[col] > (Q3 + 1.5 * IQR))).sum()
                    report['outliers'][col] = int(outliers)
        
        # Date range
        time_col = None
        for col in ['time', 'Time', 'TIME', 'timestamp', 'Timestamp']:
            if col in self.raw_data.columns:
                time_col = col
                break
        
        if time_col:
            try:
                self.raw_data[time_col] = pd.to_datetime(self.raw_data[time_col], errors='coerce')
                valid_dates = self.raw_data[time_col].dropna()
                if len(valid_dates) > 0:
                    report['date_range'] = {
                        'start': str(valid_dates.min()),
                        'end': str(valid_dates.max()),
                        'duration_days': int((valid_dates.max() - valid_dates.min()).days)
                    }
            except:
                pass
        
        # Calculate quality score
        quality_score = 100
        if 'kWh' in report['missing_values']:
            quality_score -= min(report['missing_values']['kWh'].get('percentage', 0), 20)
        quality_score -= min((report['duplicates'] / len(self.raw_data)) * 100 if len(self.raw_data) > 0 else 0, 10)
        report['quality_score'] = round(max(quality_score, 0), 2)
        
        self.quality_report = report
        print(f"âœ… Data Quality Score: {report['quality_score']}/100")
        return report
    
    def preprocess_data(self):
        """Clean and prepare data for analysis"""
        print("\nðŸ§¹ Preprocessing data...")
        
        df = self.raw_data.copy()
        
        # Find time column
        time_col = None
        for col in ['time', 'Time', 'TIME', 'timestamp', 'Timestamp']:
            if col in df.columns:
                time_col = col
                break
        
        if time_col:
            df[time_col] = pd.to_datetime(df[time_col], errors='coerce')
            df = df.dropna(subset=[time_col])
            df = df.rename(columns={time_col: 'time'})
        else:
            # Create time column from year, month, day if available
            if all(col in df.columns for col in ['year', 'month', 'day']):
                df['time'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')
                df = df.dropna(subset=['time'])
        
        # Find energy columns
        energy_col = None
        for col in ['kWh', 'kwh', 'KW', 'energy', 'Energy']:
            if col in df.columns:
                energy_col = col
                break
        
        if energy_col and energy_col != 'kWh':
            df['kWh'] = pd.to_numeric(df[energy_col], errors='coerce')
        
        if 'kWh' not in df.columns:
            # Use first numeric column
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                df['kWh'] = pd.to_numeric(df[numeric_cols[0]], errors='coerce')
        
        # Find power column
        power_col = None
        for col in ['kW', 'kw', 'power', 'Power']:
            if col in df.columns:
                power_col = col
                break
        
        if power_col and power_col != 'kW':
            df['kW'] = pd.to_numeric(df[power_col], errors='coerce')
        
        if 'kW' not in df.columns and 'kWh' in df.columns:
            df['kW'] = df['kWh']  # Use kWh as kW if kW not available
        
        # Handle missing values
        df['kWh'] = pd.to_numeric(df['kWh'], errors='coerce')
        df['kW'] = pd.to_numeric(df['kW'], errors='coerce')
        
        # Fill missing values
        df['kWh'] = df['kWh'].fillna(method='ffill').fillna(method='bfill').fillna(0)
        df['kW'] = df['kW'].fillna(method='ffill').fillna(method='bfill').fillna(0)
        
        # Remove duplicates
        if 'time' in df.columns:
            df = df.drop_duplicates(subset=['time'], keep='first')
            df = df.sort_values('time').reset_index(drop=True)
        
        # Add temporal features
        if 'time' in df.columns:
            df['hour'] = df['time'].dt.hour
            df['day_of_week'] = df['time'].dt.dayofweek
            df['day_of_month'] = df['time'].dt.day
            df['week_of_year'] = df['time'].dt.isocalendar().week
            df['month'] = df['time'].dt.month
            df['season'] = df['month'].apply(lambda x: (x % 12) // 3 + 1)  # 1=Spring, 2=Summer, 3=Fall, 4=Winter
            df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
            
            # Add rolling statistics
            df['kWh_rolling_mean_24h'] = df['kWh'].rolling(window=min(48, len(df)), min_periods=1).mean()
            df['kWh_rolling_std_24h'] = df['kWh'].rolling(window=min(48, len(df)), min_periods=1).std()
            df['kW_rolling_mean_24h'] = df['kW'].rolling(window=min(48, len(df)), min_periods=1).mean()
        
        self.clean_data = df
        print(f"âœ… Preprocessed {len(df)} records")
        return df
    
    def detect_anomalies(self):
        """Detect anomalies using Isolation Forest"""
        print("\nðŸš¨ Detecting anomalies...")
        
        df = self.clean_data.copy()
        
        # Features for anomaly detection
        features = []
        for col in ['kWh', 'kW', 'hour', 'day_of_week', 'is_weekend']:
            if col in df.columns:
                features.append(col)
        
        if len(features) == 0:
            features = df.select_dtypes(include=[np.number]).columns.tolist()[:5]
        
        X = df[features].fillna(0)
        
        # Normalize features
        X_scaled = self.scaler.fit_transform(X)
        
        # Isolation Forest
        iso_forest = IsolationForest(
            contamination=0.05,
            random_state=42,
            n_estimators=100
        )
        
        df['anomaly'] = iso_forest.fit_predict(X_scaled)
        df['anomaly_score'] = iso_forest.score_samples(X_scaled)
        df['is_anomaly'] = (df['anomaly'] == -1).astype(int)
        
        anomaly_count = df['is_anomaly'].sum()
        anomaly_pct = (anomaly_count / len(df)) * 100 if len(df) > 0 else 0
        
        self.anomalies = df[df['is_anomaly'] == 1].copy()
        self.clean_data = df
        
        print(f"âœ… Found {anomaly_count} anomalies ({anomaly_pct:.2f}%)")
        return self.anomalies
    
    def create_features_for_prediction(self, df):
        """Create features for machine learning model"""
        features = []
        for col in ['hour', 'day_of_week', 'day_of_month', 'week_of_year', 'month', 'season',
                   'is_weekend', 'kWh_rolling_mean_24h', 'kWh_rolling_std_24h', 'kW_rolling_mean_24h']:
            if col in df.columns:
                features.append(col)
        
        if len(features) == 0:
            features = df.select_dtypes(include=[np.number]).columns.tolist()[:8]
        
        X = df[features].fillna(method='ffill').fillna(0)
        
        if 'kWh' in df.columns:
            y = df['kWh']
        else:
            y = df.iloc[:, 0] if len(df.columns) > 0 else pd.Series([0] * len(df))
        
        return X, y
    
    def train_forecast_model(self, model_type=None):
        """Train forecasting model based on selected type"""
        if model_type is None:
            model_type = self.model_type
        
        print(f"\nðŸ¤– Training {model_type} forecasting model...")
        
        if len(self.clean_data) < 20:
            print("âš ï¸ Insufficient data for model training")
            return None, None, None
        
        # Split data
        split_idx = int(len(self.clean_data) * 0.8)
        train_data = self.clean_data.iloc[:split_idx]
        test_data = self.clean_data.iloc[split_idx:]
        
        # Create features
        X_train, y_train = self.create_features_for_prediction(train_data)
        X_test, y_test = self.create_features_for_prediction(test_data)
        
        # Train model based on type
        if model_type in ['CNN', 'LSTM', 'TFT']:
            # Use RandomForest as fallback for now (deep learning requires more setup)
            print(f"âš ï¸ {model_type} requires additional setup, using RandomForest instead")
            model_type = 'RandomForest'
        
        if model_type == 'RandomForest':
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=15,
                min_samples_split=5,
                random_state=42,
                n_jobs=-1
            )
        else:
            self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        
        self.model.fit(X_train, y_train)
        y_pred = self.model.predict(X_test)
        
        # Calculate metrics
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-10))) * 100
        
        metrics = {
            'MAE': round(mae, 2),
            'RMSE': round(rmse, 2),
            'R2': round(r2, 4),
            'MAPE': round(mape, 2),
            'model_type': model_type
        }
        
        print(f"âœ… Model trained - RÂ²: {r2:.4f}, MAE: {mae:.2f} kWh")
        return metrics, test_data, y_pred
    
    def generate_future_predictions(self, hours_ahead=168):
        """Generate future predictions"""
        print(f"\nðŸ”® Generating predictions for next {hours_ahead} hours...")
        
        if self.model is None or 'time' not in self.clean_data.columns:
            return pd.DataFrame()
        
        last_timestamp = self.clean_data['time'].max()
        last_record = self.clean_data.iloc[-1]
        
        future_predictions = []
        
        for i in range(1, hours_ahead + 1):
            future_time = last_timestamp + timedelta(hours=i)
            
            future_features = {
                'hour': future_time.hour,
                'day_of_week': future_time.dayofweek,
                'day_of_month': future_time.day,
                'week_of_year': future_time.isocalendar().week,
                'month': future_time.month,
                'season': (future_time.month % 12) // 3 + 1,
                'is_weekend': 1 if future_time.dayofweek in [5, 6] else 0,
                'kWh_rolling_mean_24h': last_record.get('kWh_rolling_mean_24h', 0),
                'kWh_rolling_std_24h': last_record.get('kWh_rolling_std_24h', 0),
                'kW_rolling_mean_24h': last_record.get('kW_rolling_mean_24h', 0)
            }
            
            # Create DataFrame with features
            feature_cols = ['hour', 'day_of_week', 'day_of_month', 'week_of_year', 
                          'month', 'season', 'is_weekend', 'kWh_rolling_mean_24h', 
                          'kWh_rolling_std_24h', 'kW_rolling_mean_24h']
            
            X_future = pd.DataFrame([{k: future_features.get(k, 0) for k in feature_cols}])
            
            # Use only features that model expects
            model_features = [col for col in X_future.columns if col in self.clean_data.columns or col in ['hour', 'day_of_week', 'day_of_month', 'week_of_year', 'month', 'season', 'is_weekend']]
            X_future = X_future[model_features]
            
            try:
                prediction = self.model.predict(X_future)[0]
            except:
                prediction = last_record.get('kWh', 0)
            
            future_predictions.append({
                'time': future_time,
                'predicted_kWh': prediction,
                'confidence_lower': prediction * 0.85,
                'confidence_upper': prediction * 1.15
            })
        
        self.predictions = pd.DataFrame(future_predictions)
        print(f"âœ… Generated {len(self.predictions)} predictions")
        return self.predictions
    
    def get_time_patterns(self):
        """Extract time patterns for infographics"""
        if 'time' not in self.clean_data.columns or 'kWh' not in self.clean_data.columns:
            return {}
        
        df = self.clean_data.copy()
        
        patterns = {
            'daily': {},
            'weekly': {},
            'monthly': {},
            'yearly': {}
        }
        
        # Daily pattern (hourly)
        if 'hour' in df.columns:
            daily_avg = df.groupby('hour')['kWh'].mean().to_dict()
            patterns['daily'] = {int(k): float(v) for k, v in daily_avg.items()}
        
        # Weekly pattern (day of week)
        if 'day_of_week' in df.columns:
            weekly_avg = df.groupby('day_of_week')['kWh'].mean().to_dict()
            patterns['weekly'] = {int(k): float(v) for k, v in weekly_avg.items()}
        
        # Monthly pattern
        if 'month' in df.columns:
            monthly_avg = df.groupby('month')['kWh'].mean().to_dict()
            patterns['monthly'] = {int(k): float(v) for k, v in monthly_avg.items()}
        
        # Yearly pattern (if we have year data)
        if 'year' in df.columns:
            yearly_avg = df.groupby('year')['kWh'].mean().to_dict()
            patterns['yearly'] = {int(k): float(v) for k, v in yearly_avg.items()}
        
        return patterns
    
    def get_heatmap_data(self):
        """Generate heatmap data (day of week x season)"""
        if 'day_of_week' not in self.clean_data.columns or 'season' not in self.clean_data.columns:
            return None
        
        df = self.clean_data.copy()
        heatmap_data = df.groupby(['day_of_week', 'season'])['kWh'].mean().reset_index()
        
        # Create matrix
        days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
        seasons = ['Spring', 'Summer', 'Fall', 'Winter']
        
        matrix = []
        for season in range(1, 5):
            row = []
            for day in range(7):
                value = heatmap_data[(heatmap_data['day_of_week'] == day) & 
                                    (heatmap_data['season'] == season)]['kWh'].mean()
                row.append(float(value) if not pd.isna(value) else 0)
            matrix.append(row)
        
        return {
            'matrix': matrix,
            'days': days,
            'seasons': seasons
        }
    
    def get_statistics(self):
        """Calculate key statistics"""
        stats = {
            'total_energy_consumed': float(self.clean_data['kWh'].sum()) if 'kWh' in self.clean_data.columns else 0,
            'average_consumption': float(self.clean_data['kWh'].mean()) if 'kWh' in self.clean_data.columns else 0,
            'peak_demand': float(self.clean_data['kW'].max()) if 'kW' in self.clean_data.columns else 0,
            'min_demand': float(self.clean_data['kW'].min()) if 'kW' in self.clean_data.columns else 0,
            'std_deviation': float(self.clean_data['kWh'].std()) if 'kWh' in self.clean_data.columns else 0,
            'total_records': len(self.clean_data),
            'anomalies_detected': int(self.clean_data['is_anomaly'].sum()) if 'is_anomaly' in self.clean_data.columns else 0,
            'data_quality_score': self.quality_report.get('quality_score', 0)
        }
        
        return stats

