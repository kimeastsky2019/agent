"""
ì´ìƒì§•í›„ ê°ì§€ AI Agent
Isolation Forest ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì´ìƒ íŒ¨í„´ íƒì§€
"""

from sklearn.ensemble import IsolationForest
import numpy as np
from datetime import datetime, timedelta
import random

# ì „ì—­ ë³€ìˆ˜ë¡œ ìµœê·¼ ì´ìƒì§•í›„ ì €ì¥
recent_anomalies = []

def generate_sample_data():
    """ìƒ˜í”Œ ì—ë„ˆì§€ ë°ì´í„° ìƒì„±"""
    data = []
    for i in range(100):
        # ì •ìƒ íŒ¨í„´
        value = 50 + np.random.normal(0, 10)
        data.append(value)
    
    # ì´ìƒì¹˜ ì¶”ê°€
    data.extend([10, 150, 5, 160])  # ëª…í™•í•œ ì´ìƒì¹˜
    
    return np.array(data).reshape(-1, 1)

async def detect_anomalies():
    """ì´ìƒì§•í›„ ê°ì§€ ì‹¤í–‰"""
    global recent_anomalies
    
    print("ğŸ” ì´ìƒì§•í›„ ê°ì§€ ì‹œì‘...")
    
    # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
    data = generate_sample_data()
    
    # Isolation Forest ëª¨ë¸
    model = IsolationForest(
        contamination=0.05,  # 5%ì˜ ë°ì´í„°ë¥¼ ì´ìƒì¹˜ë¡œ ì˜ˆìƒ
        random_state=42
    )
    
    # í•™ìŠµ ë° ì˜ˆì¸¡
    predictions = model.fit_predict(data)
    scores = model.score_samples(data)
    
    # ì´ìƒì¹˜ íƒì§€ (predictionì´ -1ì¸ ê²½ìš°)
    anomaly_indices = np.where(predictions == -1)[0]
    
    # ìµœê·¼ ì´ìƒì§•í›„ ì—…ë°ì´íŠ¸
    recent_anomalies.clear()
    
    for idx in anomaly_indices[-5:]:  # ìµœê·¼ 5ê°œë§Œ ì €ì¥
        severity = "high" if scores[idx] < -0.5 else "medium" if scores[idx] < -0.3 else "low"
        
        anomaly = {
            "id": len(recent_anomalies) + 1,
            "type": "warning" if severity != "low" else "info",
            "title": "ë¹„ì •ìƒì ì¸ ì „ë ¥ ë³€ë™ ê°ì§€" if severity != "low" else "ìƒì‚°ëŸ‰ ë³€ë™ ê°ì§€",
            "description": f"ì˜ˆìƒë³´ë‹¤ {random.randint(20, 40)}% {'ë‚®ì€' if random.random() > 0.5 else 'ë†’ì€'} ì „ë ¥ ìƒì‚°",
            "timestamp": (datetime.now() - timedelta(hours=random.randint(0, 5))).isoformat(),
            "severity": severity,
            "confidence": round(abs(scores[idx]) * 100, 2),
            "value": float(data[idx][0])
        }
        recent_anomalies.append(anomaly)
    
    print(f"âœ… ì´ìƒì§•í›„ {len(anomaly_indices)}ê°œ ê°ì§€ ì™„ë£Œ")
    return recent_anomalies

def get_recent_anomalies():
    """ìµœê·¼ ì´ìƒì§•í›„ ì¡°íšŒ"""
    if not recent_anomalies:
        # ì´ˆê¸° ìƒ˜í”Œ ë°ì´í„°
        return [
            {
                "id": 1,
                "type": "warning",
                "title": "ë¹„ì •ìƒì ì¸ ì „ë ¥ ë³€ë™ ê°ì§€",
                "description": "14:30-15:00 ì‚¬ì´ ì˜ˆìƒë³´ë‹¤ 30% ë‚®ì€ ì „ë ¥ ìƒì‚°",
                "timestamp": (datetime.now() - timedelta(hours=2)).isoformat(),
                "severity": "medium",
                "confidence": 85.5,
                "value": 35.2
            },
            {
                "id": 2,
                "type": "info",
                "title": "ìƒì‚°ëŸ‰ ì˜ˆì¸¡",
                "description": "ì˜¤ëŠ˜ ì´ ìƒì‚°ëŸ‰ ì˜ˆìƒ: 85.3 kWh (í‰ê·  ëŒ€ë¹„ +5%)",
                "timestamp": (datetime.now() - timedelta(hours=4)).isoformat(),
                "severity": "low",
                "confidence": 92.3,
                "value": 85.3
            }
        ]
    return recent_anomalies

def analyze_pattern(data):
    """íŒ¨í„´ ë¶„ì„"""
    # ì¶”ì„¸ ë¶„ì„
    if len(data) < 2:
        return "insufficient_data"
    
    trend = np.polyfit(range(len(data)), data.flatten(), 1)[0]
    
    if trend > 0.5:
        return "increasing"
    elif trend < -0.5:
        return "decreasing"
    else:
        return "stable"
